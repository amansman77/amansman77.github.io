---
layout: work
title: "AI 플랫폼 개발 및 MLOps 구축"
date: 2021-08-01
description: "엔키스, 지어소프트, 엠아이큐브솔루션에서 AI 서비스 플랫폼을 구축하고 MLOps 환경을 구축하여 AI 모델의 학습부터 배포까지 전 과정을 자동화했습니다."
image: "/assets/images/ai-platform-og.png"
permalink: /work/ai-platform-development/
---

## AI 플랫폼 개발 및 MLOps 구축

### 1. 문제 (Problem)

AI 기술의 발전과 함께 다양한 AI 모델이 개발되었지만, 이를 실제 서비스에 적용하고 운영하는 과정에서 다음과 같은 문제에 직면했습니다:

- **AI 모델 배포의 복잡성**: 학습된 AI 모델을 서비스 환경에 배포하고 관리하는 과정이 수동적이고 복잡
- **추론 서버의 안정성 및 성능**: 대량의 추론 요청을 처리할 수 있는 고성능, 고가용성 추론 서버의 부재
- **데이터 파이프라인 구축**: AI 모델 학습 및 추론에 필요한 데이터를 수집, 전처리, 저장하는 파이프라인 구축의 어려움
- **다양한 AI 프레임워크 지원**: TensorFlow, PyTorch 등 다양한 AI 프레임워크로 개발된 모델을 통합하여 서빙할 수 있는 유연한 구조 필요

### 2. 해결 (Solution)

이러한 문제들을 해결하기 위해 AI 플랫폼을 다음과 같이 개발하고 운영했습니다:

#### DataLake 플랫폼 (지어소프트, 2020.05 ~ 2021.05)
- **Springboot + VueJS 관리 서비스**: 데이터 관리 및 모니터링을 위한 웹 인터페이스
- **Python 데이터 처리 파이프라인**: 데이터 수집, 전처리, 특징 추출, 저장 자동화
- **SpringWebflux 자율주행 이미지 데이터 전송 서버**: NIA 프로젝트를 위한 고성능 데이터 전송
- **Kafka Cluster 구성**: 대용량 데이터 스트리밍 처리
- **MongoDB Cluster 구성**: NoSQL 데이터 저장소 구축
- **PostgreSQL HA 구성**: PGPool을 활용한 고가용성 데이터베이스
- **Rook-Ceph H/W 수준 HA**: 하드웨어 수준의 고가용성 적용
- **Object Storage 구성**: 대용량 파일 저장소 구축
- **Supervisely 연계**: 객체 어노테이션 작업 환경 구성

#### AI O&M 플랫폼
- **Triton Inference 서버**: 다양한 AI 모델을 효율적으로 서빙하는 환경 구축
- **Tensorflow & PyTorch 모델 통합**: 동일한 추론 서버에서 다양한 프레임워크 모델 구동 검증
- **NEXUS AI 모델 Repository**: AI 모델 버전 관리 및 저장소

#### Edge AI 플랫폼
- **라즈베리파이 K3S 클러스터**: IoT 환경을 위한 경량 컨테이너 클러스터
- **모델 운영환경 구성**: Tensorflow, Tensorflow Serving, Tensorflow Lite, TensorRT 연구
- **NVIDIA Jetson NANO**: 엣지 환경에서의 AI 모델 운영환경 구성
- **NVIDIA DeepStream**: 데이터 파이프라인 구조 설계 및 벤치마킹
- **MQTT(Mosquitto)**: 데이터 스트림 구성을 위한 메시징 시스템

#### MLOps 플랫폼
- **우버, 구글 클라우드, INNOQ, AWS 분석**: 최적의 MLOps 아키텍처 설계
- **Kubernetes CPU/GPU 클러스터**: 하이브리드 컴퓨팅 환경 구축
- **Gitlab CI/CD 파이프라인**: AI 모델 학습부터 배포까지 자동화
- **Prometheus & Grafana**: 서비스 모니터링 및 성능 지표 시각화

#### 실시간 AI 추론 환경 (엠아이큐브솔루션, 2019.06 ~ 2020.04)
- **센서 데이터 수집**: IoT 센서로부터 실시간 데이터 수집
- **수집 데이터 백업**: 데이터 손실 방지를 위한 백업 시스템
- **AI 모델 구동**: 실시간 추론을 위한 모델 서빙
- **AI 모델 결과 분석**: 추론 결과 분석 및 후처리
- **알람 전송**: 이상 상황 발생 시 즉시 알림
- **관리자 페이지**: RestfulAPI 서버 + VueJS 기반 웹 서비스

### 3. 결과 (Results)

#### 기술적 성과
- **AI플랫폼 v0.2 릴리즈**: DataLake PoC, Edge AI PoC, 추론 운용환경 PoC 완료
- **실시간 AI 추론환경 PoC**: 센서 데이터부터 결과 분석까지 전 과정 자동화
- **다양한 AI 프레임워크 통합**: TensorFlow, PyTorch 모델을 동일한 환경에서 서빙
- **고가용성 인프라**: H/W 수준의 HA를 통한 안정적인 서비스 운영

#### 비즈니스 성과
- **NIPA, NIA 과제 수행**: 정부 과제를 플랫폼 기반으로 성공적 수행
- **광주 R&BD 수행**: 지역 연구개발 과제 수행
- **자율주행 이미지 데이터 처리**: NIA 프로젝트를 통한 대용량 데이터 처리

#### 운영 효율성
- **MLOps 자동화**: AI 모델 학습부터 배포까지 전 과정 자동화
- **모니터링 시스템**: Prometheus & Grafana를 통한 실시간 모니터링
- **CI/CD 파이프라인**: Gitlab을 활용한 지속적 통합 및 배포

### 4. 나의 역할 및 인사이트 (My Role & Insights)

**역할**: 
- **엔키스** (2021.05 ~ 2021.08): AI 서비스플랫폼팀 책임
- **지어소프트** (2020.05 ~ 2021.05): AI플랫폼 개발실 책임
- **엠아이큐브솔루션** (2019.06 ~ 2020.04): Digital Factory Lab 책임
- AI 플랫폼 기획 (30%), 설계 (30%), 개발 (30%), 성능 테스트 (10%)

**인사이트**: 
AI 플랫폼 개발을 통해 AI 모델 개발만큼이나 중요한 것이 모델을 안정적으로 서빙하고 운영할 수 있는 플랫폼의 중요성임을 깨달았습니다. 특히 다양한 AI 기술 스택을 통합하고 관리하는 과정에서 시스템의 유연성과 확장성을 고려하는 것이 핵심이었습니다.

MLOps의 중요성도 크게 느꼈습니다. 단순히 AI 모델을 개발하는 것을 넘어서, 모델의 학습부터 배포, 모니터링까지 전 과정을 자동화하는 것이 실제 서비스에서 AI를 활용하기 위한 필수 요소라는 것을 배웠습니다. 

Edge AI 플랫폼 구축을 통해 IoT 환경에서의 AI 서빙의 복잡성도 경험했습니다. 라즈베리파이와 같은 제한된 리소스 환경에서도 안정적으로 AI 모델을 서빙할 수 있는 방법을 연구하고 구현할 수 있었습니다.

이 프로젝트들을 통해 AI 기술의 실무 적용에 대한 깊은 이해를 얻을 수 있었고, 단순한 기술 구현을 넘어서 비즈니스 가치를 창출할 수 있는 AI 플랫폼을 구축하는 경험을 할 수 있었습니다.
